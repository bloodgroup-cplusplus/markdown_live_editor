## **Load Balancing Basics \- The Traffic Director**

### **ğŸ¯ Challenge 4: The Restaurant Host Problem**

**Scenario:** You own a restaurant with 5 identical dining rooms. Customers arrive at the entrance.

**Without a host:**

Entrance
   â”‚

            â–¼

Room 1: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ (packed, 30 min wait)

Room 2: â–ˆâ–ˆâ–ˆâ–ˆ         (some people)

Room 3: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ (packed)

Room 4: â–ˆâ–ˆ           (almost empty\!)

Room 5: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ (packed)

Problem: Customers just pick random rooms\!
Result: Long waits, unhappy customers, empty tables

**With a smart host:**

Entrance

   â”‚

   â–¼

  Host (sees all rooms, directs customers smartly)

   â”œâ”€â†’ Room 1: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  (balanced)

   â”œâ”€â†’ Room 2: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  (balanced)

   â”œâ”€â†’ Room 3: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  (balanced)

   â”œâ”€â†’ Room 4: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  (balanced)

   â””â”€â†’ Room 5: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  (balanced)

Result: No waits, happy customers, efficient\!

**This is exactly what a Load Balancer does\!**

---

### **ğŸ—ï¸ What is Load Balancing?**

**Definition:** A load balancer is like a smart traffic director that distributes incoming requests across multiple servers.

![img1](https://res.cloudinary.com/dretwg3dy/image/upload/v1764771695/262_rajp5f.png)

All servers: Happy and balanced\!

**Key Insight:** Load balancers prevent any single server from being overwhelmed\!

---

### **ğŸ® Interactive Exercise: Load Balancing Algorithms**

**Scenario:** You have 3 servers. 9 requests arrive. How do you distribute them?

Let's explore different strategies:

#### **Algorithm 1: Round Robin ğŸ”„**

**How it works:** "Take turns, like dealing cards"

![img2](https://res.cloudinary.com/dretwg3dy/image/upload/v1764771695/254_ggpk1u.png)

Perfect equality\!

**Pros:** Simple, fair, easy to implement **Cons:** Doesn't consider server load or speed

**Real-world example:** Like handing out homework to students in seat order

---

#### **Algorithm 2: Least Connections ğŸ“Š**

**How it works:** "Send to whoever is least busy right now"

Starting state:

Server 1: 2 active connections

Server 2: 5 active connections

Server 3: 1 active connection

![img3](https://res.cloudinary.com/dretwg3dy/image/upload/v1764773305/load_balance_zj4bnd.png)

New request arrives:

â†’ Check all servers

â†’ Server 3 has fewest connections (1)

â†’ Send request to Server 3\!

![img4](https://res.cloudinary.com/dretwg3dy/image/upload/v1764771696/258_e36d0v.png)

**Pros:** Accounts for different request durations

**Cons:** Slightly more complex, needs to track connections


**Real-world example:** Like a grocery store checkout \- you join the shortest line\!

---

#### **Algorithm 3: Weighted Distribution âš–ï¸**

**How it works:** "Better servers get more work"

Server setup:

Server 1: Power rating 5 (newest, most powerful)

Server 2: Power rating 3 (medium)

Server 3: Power rating 2 (older, slower)

Total power: 10

Distribution ratio: 5:3:2

For 100 requests:

Server 1 gets: 50 requests (50%)

Server 2 gets: 30 requests (30%)

Server 3 gets: 20 requests (20%)

![img5](https://res.cloudinary.com/dretwg3dy/image/upload/v1764771695/256_ax9fjr.png)

**Pros:** Utilizes hardware differences efficiently

**Cons:** Requires knowing server capabilities


**Real-world example:** Like a restaurant assigning more tables to experienced waiters

---

#### **Algorithm 4: IP Hash ğŸ”**

**How it works:** "Same client always goes to same server"

How hashing works:

User IP: 192.168.1.100

â†’ Hash function: hash(192.168.1.100) \= 347

â†’ 347 % 3 \= 2  (modulo number of servers)

â†’ Always routes to Server 2\!

Same user's next request:

â†’ hash(192.168.1.100) \= 347  (same\!)

â†’ 347 % 3 \= 2

â†’ Server 2 again\!

Different user IP: 192.168.1.101

â†’ hash(192.168.1.101) \= 892

â†’ 892 % 3 \= 1

â†’ Routes to Server 1

![img6](https://res.cloudinary.com/dretwg3dy/image/upload/v1764771695/261_cklgsr.png))

**Pros:**

* Session persistence (user's data cached on one server)
* Predictable routing

**Cons:**

* Uneven distribution if many users from same IP range
* Server failure requires rehashing

**Real-world example:** Like having a regular doctor \- you always see the same one who knows your history

---

### **ğŸ’¡ Types of Load Balancers: Layer 4 vs Layer 7**

ğŸ”Œ LAYER 4 (Network Load Balancer)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Works at: TCP/UDP level

Sees: IP addresses, ports

Fast: Very (just forwards packets)

Smart: Not very

Example decision:

![img7](https://res.cloudinary.com/dretwg3dy/image/upload/v1764771696/257_ikxhju.png)

Use when: Raw speed needed, simple TCP routing

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸŒ LAYER 7 (Application Load Balancer)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Works at: HTTP/HTTPS level

Sees: URLs, headers, cookies, content

Fast: Slower (must read HTTP)

Smart: Very\!

Example decision:
"This request is for /api/users"
â†’ Route to API servers

"This request is for /images/cat.jpg"
â†’ Route to image servers

      Internet
         â”‚
         â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Layer 7 â”‚  "GET /api/users"
    â”‚   LB    â”‚  â†’ Route to API cluster
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚       "GET /static/logo.png"
         â”‚       â†’ Route to CDN servers
         â”‚
    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”
    â–¼          â–¼
\[API Servers\] \[Static Servers\]

Use when: Need smart routing by content

**Real-world comparison:**

* **Layer 4:** Like a highway toll booth \- just directs cars, doesn't care what's inside

* **Layer 7:** Like a smart receptionist \- reads your request and directs you to the right department

### **ğŸš¨ Common Misconception: "Load Balancers Never Fail"**

**You might think:** "Great\! Load balancer solves everything\!"

**The Reality:** Load balancers themselves can fail or become bottlenecks\!

**The Solution: Multiple Load Balancers\!**

âŒ SINGLE LOAD BALANCER (Risky\!)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

![img8](https://res.cloudinary.com/dretwg3dy/image/upload/v1764771696/257_ikxhju.png)

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

âœ… REDUNDANT LOAD BALANCERS (Safe\!)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

![img9](https://res.cloudinary.com/dretwg3dy/image/upload/v1764771695/255_i2kk9d.png)

Safety: If LB 1 fails, LB 2 continues\!

---

### **ğŸª Real-World Load Balancing Architecture**

**Let's see how a real company like Netflix might structure their load balancing:**

ğŸŒ GLOBAL ARCHITECTURE

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

![img10](https://res.cloudinary.com/dretwg3dy/image/upload/v1764771696/260_rfic9f.png)

Each zone has:

â”œâ”€ Layer 4 Load Balancer (Network LB) â† Third layer: TCP routing

â”œâ”€ 50+ Web Servers

â”œâ”€ 20+ API Servers

â””â”€ 10+ Database Read Replicas

**Why multiple layers?**


1. **DNS Layer:** Routes by geography (latency optimization)

2. **Application Layer (L7):** Routes by URL path, HTTP headers

3. **Network Layer (L4):** Raw TCP connection distribution

---

### **ğŸ” Investigation: What Happens When a Server Dies?**

**Scenario:** You have 4 servers behind a load balancer. Server 3 crashes.

**Without Health Checks:**

Load Balancer: "Round robin time\!"

Request 1 â†’ Server 1 âœ… (works)

Request 2 â†’ Server 2 âœ… (works)

Request 3 â†’ Server 3 âŒ (DEAD\! User sees error)

Request 4 â†’ Server 4 âœ… (works)

Request 5 â†’ Server 1 âœ… (works)

Request 6 â†’ Server 2 âœ… (works)

Request 7 â†’ Server 3 âŒ (STILL DEAD\! Another error)

Result: 25% of requests fail\! ğŸ˜¡

**With Health Checks (Smart\!):**

Health Check Configuration:

\- Check every 10 seconds

\- Send HTTP GET to /health

\- Expect 200 OK response

\- If fails 3 times â†’ Mark unhealthy

Timeline:
10:00:00 \- Server 3 crashes

10:00:10 \- Health check fails (1/3)

10:00:20 \- Health check fails (2/3)

10:00:30 \- Health check fails (3/3) â†’ REMOVED\!

Load Balancer: "Server 3 is out\! Skip it\!"

Request 1 â†’ Server 1 âœ…

Request 2 â†’ Server 2 âœ…

Request 3 â†’ Server 4 âœ… (skipped dead Server 3\!)

Request 4 â†’ Server 1 âœ…

Request 5 â†’ Server 2 âœ…

Result: 0% failures\! ğŸ‰

10:05:00 \- Server 3 comes back online
10:05:10 \- Health check succeeds (1/3)
10:05:20 \- Health check succeeds (2/3)
10:05:30 \- Health check succeeds (3/3) â†’ ADDED BACK\!

Load Balancer: "Welcome back, Server 3\!"

**Key Insight:** Health checks are CRITICAL for reliability\!

---

---

### **ğŸ¯ Decision Game: Choose Your Algorithm**

**For each scenario, pick the best load balancing algorithm:**

**Scenario A:** Simple website, all servers identical

**Scenario B:** Video encoding \- jobs take 5 seconds to 5 minutes

**Scenario C:** Shopping cart \- need same user to hit same server

**Scenario D:** 1 new powerful server \+ 2 older slower servers

**Scenario E:** API with completely independent requests

**Think carefully...**

---

**ANSWERS:**

Scenario A: ROUND ROBIN âœ“

Why: Servers identical, simple is best

Scenario B: LEAST CONNECTIONS âœ“

Why: Job duration varies widely, need dynamic balancing

Scenario C: IP HASH âœ“

Why: Session persistence required for cart data

Scenario D: WEIGHTED âœ“

Why: Different server capabilities

Config: New server weight=5, old servers weight=2 each

Scenario E: ROUND ROBIN or RANDOM âœ“

Why: Stateless, any algorithm works fine

---

### **ğŸª The Complete Picture: Load Balancer Features**

MODERN LOAD BALANCER CAPABILITIES

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âœ… Traffic Distribution

   â”œâ”€ Round Robin

   â”œâ”€ Least Connections

   â”œâ”€ Weighted

   â””â”€ IP Hash

âœ… Health Monitoring

   â”œâ”€ HTTP health checks

   â”œâ”€ TCP health checks

   â”œâ”€ Custom health endpoints

   â””â”€ Automatic server removal/re-addition

âœ… SSL/TLS Termination

   â”œâ”€ Handle HTTPS encryption

   â”œâ”€ Decrypt at load balancer

   â””â”€ Send plain HTTP to backend
      (reduces server CPU load)

âœ… Sticky Sessions

   â”œâ”€ Cookie-based routing

   â””â”€ Keep user on same server

âœ… Rate Limiting

   â”œâ”€ Protect from DDoS

   â””â”€ Throttle aggressive clients

âœ… Geographic Routing

   â”œâ”€ Route EU users to EU servers

   â””â”€ Minimize latency

âœ… Content-Based Routing

   â”œâ”€ /api/\* â†’ API servers

   â”œâ”€ /images/\* â†’ Image servers

   â””â”€ /admin/\* â†’ Admin servers

âœ… Metrics & Logging

   â”œâ”€ Request counts

   â”œâ”€ Response times

   â””â”€ Error rates

---

### **ğŸ”‘ Key Takeaways: Load Balancing**

ğŸ“ REMEMBER:

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

1ï¸âƒ£ Load balancers distribute traffic across servers

2ï¸âƒ£ Multiple algorithms for different needs:

   â€¢ Round Robin â†’ Simple rotation

   â€¢ Least Connections â†’ Dynamic balancing

   â€¢ Weighted â†’ Different server capabilities

   â€¢ IP Hash â†’ Session persistence

3ï¸âƒ£ Health checks prevent routing to dead servers

4ï¸âƒ£ Layer 4 \= Fast & simple (TCP/IP)
   Layer 7 \= Smart & content-aware (HTTP)

5ï¸âƒ£ Load balancers themselves need redundancy\!

6ï¸âƒ£ Essential for horizontal scaling

ğŸ¯ One sentence: "Load balancers are traffic directors
    that ensure no server gets overwhelmed and every
    request reaches a healthy server"
